# -*- coding: utf-8 -*-
"""CSE422 Final Lab Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IWTs61XKeF2V5Y6um0BHPnCzHSr3kCqz

## Mount Drive, Load Data from CSV File & Import Libraries
"""

import pandas as pd
import numpy as np
from google.colab import drive

drive.mount('/content/gdrive')

data = pd.read_csv("/content/gdrive/MyDrive/BRACU/Semesters/Sem 07 (Fall23)/CSE422/Labs/cse422-lab-project/dataset/Telco-Customer-Churn - Telco-Customer-Churn.csv")
data.head(10)

"""## Dataset Analyse & Preprosessing & Feature Selection




"""

data.shape

data.isnull().sum()

"""### Dropping unnecessary columns or features
So we can see, we have:
- 7043 individual entries or rows with 25 coulumns.
- The first 24 columns are our features and the last column `Churn` is our class.
- Here the `customerID` feature doesn't seem to contribute anything as all the customers have unique IDs, so we will not find any pattern here. As a result it's better to drop the column `customerID`
- Then the columns `HaveDog`, `WatchNetflix`, `UseTiktok`, `FeelsLonely` doesn't seem to have any values in it, all the entries of these columns are null. So it's better to drop these columns as well.
"""

print("Shape of dataframe before dropping any features:", data.shape)
data = data.drop(['customerID', 'HaveDog', 'WatchNetflix', 'UseTiktok', 'FeelsLonely'], axis = 1)
print("Shape of dataframe after dropping unnecessary features:", data.shape)
data.isnull().sum()

"""### Dropping Entries with Duplicate Values"""

data.duplicated().sum()

print("Shape of dataframe before dropping duplicate entries", data.shape)
data.drop_duplicates(inplace=True)
print("Shape of dataframe after dropping duplicate entries", data.shape)

"""### Removing Rows with Null Values
Now we can see in some of the entries there are some null values, or we can say for some entries there are some features without any value. So we can just remove those entries or rows without remove a whole column for it. But we will not remove rows with null value in `StreamingTV` or `TotalCharges` column, as it will result in a great dataloss. We don't wanna do that, instead we will impute those null fields. First let's drop the entries with null values, other than `StreamingTV` or `TotalCharges` column.
"""

print("Shape of dataframe before dropping null rows:", data.shape)
data = data.dropna(axis = 0, subset = ['gender', 'Partner', 'Dependents', 'tenure', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges'])
print("Shape of dataframe after dropping null rows:", data.shape)
data.isnull().sum()

"""### Imputing Entries with Null Value in the Columns `StreamingTV` & `TotalCharges`"""

from sklearn.impute import SimpleImputer
print("Shape of dataframe before imputng the dataset:", data.shape)

imputeSteamingTV = SimpleImputer(missing_values=np.nan, strategy='most_frequent')

imputeSteamingTV.fit(data[['StreamingTV']])

data['StreamingTV']  = imputeSteamingTV.transform(data[['StreamingTV']])

imputeTotalCharges = SimpleImputer(missing_values=np.nan, strategy='mean')

imputeTotalCharges.fit(data[['TotalCharges']])

data['TotalCharges']  = imputeTotalCharges.transform(data[['TotalCharges']])

print("Shape of dataframe after imputng the dataset:", data.shape)
data.isnull().sum()

"""### Splitting Dataset

"""

from sklearn.model_selection import train_test_split

X = data.drop(columns = ['Churn'])
y = data['Churn'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)

print("=============== X Train ===============")
cols_to_show = ['gender', 'Dependents', 'PaperlessBilling', 'Contract', 'TotalCharges']
print(X_train[cols_to_show])
print("=============== Y Train ===============")
print(y_train)

"""### Encoding Categorical Data & Scale Numeric Data"""

data.info()

"""We see 3 features with numeric values
- `tenure`
- `MonthlyCharges`
- `TotalCharges`

We will scale these 3 feature columns. And will categorically encode all the other columns as all the other columns contains categorical values.
"""

from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Define the numeric and categorical columns
numeric_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']
categorical_columns = [col for col in X_train.columns if col not in numeric_columns]

# Create transformers
numeric_transformer = Pipeline(steps=[
    ('scaler', MinMaxScaler())])

categorical_transformer = Pipeline(steps=[
    ('encoder', OrdinalEncoder())])

# Combine transformers
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_columns),
        ('cat', categorical_transformer, categorical_columns)])

# Fit and transform the data
X_train = preprocessor.fit_transform(X_train)

# Encoding y_train as well
le = LabelEncoder()
y_train = le.fit_transform(y_train)

print("=============== X Train Encoded ===============")
print(X_train)
print("=============== Y Train Encoded ===============")
print(y_train)

"""## Implementing ML Models

### Implementing Decision Tree
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Create a decision tree classifier object
clf = DecisionTreeClassifier()

# Train the model
clf.fit(X_train, y_train)

# Predict on the test data
X_test_processed = preprocessor.transform(X_test)
y_test_processed = le.transform(y_test)
y_pred = clf.predict(X_test_processed)

# Calculate accuracy
accuracy_using_decision_tree = accuracy_score(y_test_processed, y_pred)

print("Model accuracy using Decision Tree: ", round(accuracy_using_decision_tree*100, 2), "%")

"""### Implementing Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Create a random forest classifier object
clf = RandomForestClassifier()

# Train the model
clf.fit(X_train, y_train)

# Predict on the test data
X_test_processed = preprocessor.transform(X_test)
y_test_processed = le.transform(y_test)
y_pred = clf.predict(X_test_processed)

# Calculate accuracy
accuracy_using_random_forest = accuracy_score(y_test_processed, y_pred)

print("Model accuracy using Random Forest: ", round(accuracy_using_random_forest*100, 2), "%")

"""### Implementing Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Create a logistic regression object
clf = LogisticRegression()

# Train the model
clf.fit(X_train, y_train)

# Predict on the test data
X_test_processed = preprocessor.transform(X_test)
y_test_processed = le.transform(y_test)
y_pred = clf.predict(X_test_processed)

# Calculate accuracy
accuracy_using_logistic_regression = accuracy_score(y_test_processed, y_pred)

print("Model accuracy using Logistic Regression: ", round(accuracy_using_logistic_regression*100, 2), "%")

"""### Implementing Gaussian Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

# Create a Gaussian Naive Bayes classifier object
clf = GaussianNB()

# Train the model
clf.fit(X_train, y_train)

# Predict on the test data
X_test_processed = preprocessor.transform(X_test)
y_test_processed = le.transform(y_test)
y_pred = clf.predict(X_test_processed)

# Calculate accuracy
accuracy_using_gaussian_nb = accuracy_score(y_test_processed, y_pred)

print("Model accuracy using Gaussian Naive Bayes: ", round(accuracy_using_gaussian_nb*100, 2), "%")

"""## Visualising Data

### Churn: Yes vs No
In our data we ave more no's than yes. Which is a good indicator for the business.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Creating a countplot with custom colors
ax = sns.countplot(x='Churn', data=data, palette=['#fdfa72', '#fffec8'])

# Annotate the counts on top of the bars
for p in ax.patches:
    ax.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')

plt.show()

"""### Prediction Accuracy of Different Models
After comparing between the models, it seems like logistic regression performs better than any other models we have used.
"""

# Assuming you have calculated the accuracy of each model
accuracy_dict = {
    'Decision Tree': accuracy_using_decision_tree*100,
    'Random Forest': accuracy_using_random_forest*100,
    'Logistic Regression': accuracy_using_logistic_regression*100,
    'Naive Bayes': accuracy_using_gaussian_nb*100
}

# Convert the dictionary to a pandas DataFrame
accuracy_df = pd.DataFrame(list(accuracy_dict.items()), columns=['Model', 'Accuracy'])

# Create a bar plot with custom colors
plt.figure(figsize=(10, 6))
ax = sns.barplot(x='Model', y='Accuracy', data=accuracy_df, palette=['#e5c3c6', '#e1e9b7', '#f96161', '#bcd2d0'])

# Annotate the accuracy on top of the bars
for p in ax.patches:
    ax.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')

plt.show()